{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33bc9d13",
   "metadata": {},
   "source": [
    "# 1. How to get Text Data from Social Media Platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952e666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tweepy\n",
    "import tweepy, codecs\n",
    "\n",
    "# https://developer.twitter.com/en\n",
    "# https://developer.twitter.com/en/docs/tutorials/step-by-step-guide-to-making-your-first-request-to-the-twitter-api-v2\n",
    "#https://developer.twitter.com/en/docs/authentication/oauth-1-0a\n",
    "\n",
    "## fill in your Twitter credentials \n",
    "consumer_key = \"2zTYzTiZV2H2yl33sDBa51ev8\"\n",
    "consumer_secret = \"CcCrlnCCgw4tKYHgF6RSf8i6XNQiFYEmdHHQnFbi2INbBXydxi\"\n",
    "access_token = \"2256694454-NjwoZYuLo0KmOb4PCjEKobZMF4tBZ7JgiMjFtCO\"\n",
    "access_token_secret = \"lMZFp0X62MMPH150fZvEkX8CpQw7i892eOWdcUbpOXput\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03fe52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let Tweepy set up an instance of the REST API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b19848",
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1/ipykernel_28484/3674732715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create a query string to fetch tweet data(text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Virat Kohli\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"en\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"recent\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"100\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\"3500\" # 500Ktweets/month\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"My_file_twitter.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_list'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[1;34m(self, q, **kwargs)\u001b[0m\n\u001b[0;32m   1301\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \"\"\"\n\u001b[1;32m-> 1303\u001b[1;33m         return self.request(\n\u001b[0m\u001b[0;32m   1304\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[0;32m   1305\u001b[0m                 \u001b[1;34m'q'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'geocode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lang'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'locale'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'result_type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mBadRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m403\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "#Create a query string to fetch tweet data(text)\n",
    "results1 = api.search_tweets(q = \"Virat Kohli\", lang = \"en\", result_type = \"recent\", count = \"100\") #\"3500\" # 500Ktweets/month\n",
    "\n",
    "file = codecs.open(\"My_file_twitter.txt\", \"w\", \"utf-8\")\n",
    "for result in results:\n",
    "    file.write(result.text)\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34632f9",
   "metadata": {},
   "source": [
    "# 2. How to read and store text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3aa345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa9ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_table(\"My_file_twitter.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12721965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 vta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 virat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 vta\n",
       "0  2 virat"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb507dd",
   "metadata": {},
   "source": [
    "# 3. How to process text data to clean for any sort of noises present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313f99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing text data using Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f34f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# re.findall(pattern, string)\n",
    "# re.sub(pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e74bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_tweet = 'Joe said Change will not come if, we wait # for Biden $ and some other person to come and change 4 us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d14f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe']\n"
     ]
    }
   ],
   "source": [
    "find_string = re.findall('Joe',Original_tweet)\n",
    "print(find_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08915b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said Change will not come if, we wait # for Joe $ and some other person to come and change 4 us\n"
     ]
    }
   ],
   "source": [
    "find_string_2 = re.sub('Biden', 'Joe', Original_tweet)\n",
    "print(find_string_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e018080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe', 'Change', 'not', 'we', 'for', 'and', 'other', 'to', 'and']\n"
     ]
    }
   ],
   "source": [
    "Clean_tweet1 = re.findall(r'([A-Za-z]+)\\s\\w+', Original_tweet)\n",
    "print(Clean_tweet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c06c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe', 'said', 'Change', 'will', 'not', 'come', 'if', 'we', 'wait', 'for', 'Biden', 'and', 'some', 'other', 'person', 'to', 'come', 'and', 'change', 'us']\n"
     ]
    }
   ],
   "source": [
    "Clean_tweet2 = re.findall(r'[A-Za-z]+', Original_tweet)\n",
    "print(Clean_tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69191a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\s\\w+ : Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "671f24b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_tweet = \"Joe said  Change will not come if, we don't wait # for @Biden $ and some other person to come and change 4 us, please RT@Maneet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f96133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said  Change will not come if, we don't wait # for @Biden $ and some other person to come and change 4 us,  \n"
     ]
    }
   ],
   "source": [
    "Clean_tweet2 = re.sub(r'please RT@Maneet', \" \", Original_tweet)\n",
    "print(Clean_tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abed9e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said Change will not come if, we don't wait # for @Biden $ and some other person to come and change 4 us, \n"
     ]
    }
   ],
   "source": [
    "Clean_tweet3 = re.sub(r\"\\s+\",\" \", Clean_tweet2)\n",
    "print(Clean_tweet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d441e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said Change will not come if, we don't wait # for @Biden $ and some other person to come and change 4 us, \n"
     ]
    }
   ],
   "source": [
    "Clean_tweet4 = re.sub(r\"Maneet\",\" \", Clean_tweet3)\n",
    "print(Clean_tweet4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d4a1f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said Change will not come if we don't wait  for Biden  and some other person to come and change 4 us \n"
     ]
    }
   ],
   "source": [
    "Clean_tweet5 = re.sub(r\"[,@?$#!_%]\", \"\", Clean_tweet3)\n",
    "print(Clean_tweet5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7afbd871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said Change will not come if we don't wait for Biden and some other person to come and change 4 us \n"
     ]
    }
   ],
   "source": [
    "Clean_tweet6 = re.sub(r\"\\s+\",\" \", Clean_tweet5)\n",
    "print(Clean_tweet6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a235e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe said Change will not come if we don't wait for Biden and some other person to come and change us \n"
     ]
    }
   ],
   "source": [
    "Clean_tweet7 = re.sub(r\"([0-9])\",\"\", Clean_tweet6)\n",
    "Clean_tweet8 = re.sub(r\"\\s+\",\" \", Clean_tweet7)\n",
    "print(Clean_tweet8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66ec08c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe', 'said', 'Change', 'will', 'not', 'come', 'if', 'we', 'don', 't', 'wait', 'for', 'Biden', 'and', 'some', 'other', 'person', 'to', 'come', 'and', 'change', 'us']\n"
     ]
    }
   ],
   "source": [
    "Clean_tweet9 = re.findall(r'[A-Za-z]+', Clean_tweet8)\n",
    "print(Clean_tweet9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ade1ba",
   "metadata": {},
   "source": [
    "# 4. Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932419b",
   "metadata": {},
   "source": [
    "# # stem may not be an actual word (stemming’ to ‘stem’) whereas, lemma will give an actual language word - ‘Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus,’ etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c7e657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# Bring the word back to its root word by removing suffix or prefix from the current word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d68a4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824997b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "013611e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_words = [\"wait\", \"waiting\", \"waited\", \"waits\", \"awaiting\", \"lying\", \"crying\", \"Studying\", \"don't\",\"Corpora\",\"better\",\"worse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "477089fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait\n",
      "wait\n",
      "wait\n",
      "wait\n",
      "await\n",
      "lie\n",
      "cri\n",
      "studi\n",
      "don't\n",
      "corpora\n",
      "better\n",
      "wors\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for w in original_words:\n",
    "    root_word_stem = ps.stem(w)\n",
    "    print(root_word_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e6163bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "#Bring the word back to root word, more from language perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c21f8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies\n",
      "Studying\n",
      "Cry\n",
      "Cries\n",
      "wa\n",
      "Corpora\n",
      "wa\n",
      "n't\n",
      "like\n",
      "better\n",
      "worse\n"
     ]
    }
   ],
   "source": [
    "text = \"Studies Studying Cry Cries was Corpora wasn't like better worse\"\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "WLemma = WordNetLemmatizer()\n",
    "words = nltk.word_tokenize(text)\n",
    "for w in words:\n",
    "    root_word_lemma = WLemma.lemmatize(w)\n",
    "    print(root_word_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a3fe8c",
   "metadata": {},
   "source": [
    "# Home work:\n",
    "    You need to create a generic function with all the above text processing steps that we created seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8cf2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(\"Airline_Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1e7df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "363f4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a8ef876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3767df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
